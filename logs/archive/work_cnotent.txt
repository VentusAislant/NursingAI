工作汇报

一、数据处理与预处理工作
数据清洗与修正（6-12小时）

- 对病人、专家和护士的对话数据进行深入清洗；

- 修复标点错误、角色标识错误，如将【200】等非标准编号统一规范为“对话1-对话500”格式；

- 利用程序筛查对话轮数异常，辅助发现医生说话误归类问题，结合人工多轮逐条修正，需要浏览样本超过200条，修正样本超过 20 条；

数据格式化（约3-6小时）

- 编写格式化脚本，将清洗后的非结构化对话转化为结构化 JSON 格式；

- 调整格式兼容模型训练框架需求

- 脚本经过 2~3 轮优化与测试，保证其符合模型输入的需求，便于后续训练和推理阶段调用；

二、模型准备工作
模型下载与资源准备（约1天）

- 下载部署所需的大模型，包括：

	- DeepSeek-R1-DIstall-Qwen-7B

	- MMed-Llama-3-8B

- 检查模型完整性，确保模型权重完整性与环境兼容性；

三、模型代码编写与维护（持续进行中）
- 训练代码撰写与优化

- 根据不同模型和实验配置，自定义并调试训练脚本，实现不同模型结构统一训练接口，封装关键逻辑，提升复用性；

- 增加灵活参数控制，支持不同 LoRA Rank 与 Epoch 组合；

- 推理代码编写（约2-4天）： 编写模型推理代码，对训练模型进行测试评估；

四、实验设计与执行（累计GPU训练时间：约100~150小时）
参数实验设计

- LoRA Rank实验：Rank = 32 / 64 / 128，分别训练并记录表现；

- Epoch实验：Epoch = 3 / 9 / 20，检验欠拟合与过拟合的边界；

- 模型对比实验： 使用不同模型架构 DeepSeek-R1-DIstall-Qwen-7B 和 MMed-Ins-LLama3-8B 比较两者在相同任务下的表现差异；

- Prompt Tuning 对比实验（可选）

- 与不训练版本进行效果对比评估（可选）；

- 实验总计：预计训练次数至少约20~30次； 平均单次实验时间：平均约5小时（视LoRA和Epoch配置而定）；
